= 扩展应用程序
:navtitle: Scaling Apps

[#deployments_and_replication_controllers]
== 背景：部署 Deployments 和复制集 ReplicaSets

虽然服务为 Pod 提供路由和负载平衡（这些 Pod 可能会存在或不存在），但 ReplicaSet （RS） 和 ReplicationController （RC） 用于指定并确保存在所需数量的 Pod（副本）
例如，如果你总是希望你的应用程序服务器缩放到3个Pod（实例）, 一个 ReplicaSet是必须的，没有ReplicaSet的话，Pod被kill或者die，意外退出，openshift是不会自动重新启动Pod的。ReplicaSets和ReplicationController是 OpenShift“自我修复self heals”的基础， Deployments control，ReplicaSets、ReplicationController是由DeploymentConfigs控制的

来自openshift {openshift-docs-url}/applications/deployments/what-deployments-are.html[deployments 文档]，link:https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.8/html/building_applications/_deployments#deployments-repliasets_what-deployments-are[中文在这里]

[quote]
__
与复制控制器类似, ReplicaSet 是一个原生 Kubernetes API 对象，可以确保在任意给定时间运行指定数量的 pod 副本。副本集与复制控制器之间的区别在于，副本集支持基于集合的选择器要求，而复制控制器只支持基于相等的选择器要求。
__

在 Kubernetes 中，部署*Deployment* (D) 定义了应该如何部署某些东西。在几乎所有情况下，您最终都会一起使用Pod、Service、 ReplicaSet和Deployment资源。而且，在几乎所有这些情况下，OpenShift 都会为您创建所有这些。

在某些边缘情况下，您可能需要一些Pod和一个没有Deployment或Service的ReplicaSet，您可以在实验结束后随时联系红帽咨询。

[#exploring_deployment_related_objects]
== 练习：探索与部署相关的对象

现在我们知道了ReplicaSet和 Deployment的背景知识，我们可以探索它们是如何工作的以及它们之间的关系。让我们看一下您让Openshift根据您的要求，使用parksmap镜像为您运行程序时，OpenShift为您创建的部署deployment --parksmap：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get deployment
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
parksmap   1/1     1            1           20m
----

要获得更多详细信息，我们可以查看 *ReplicaSet* (*RS*).

看一下我们之前部署`parksmap` 镜像时，Openshift创建的 *ReplicaSet* (RS) 

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get rs
----

[.console-output]
[source,bash]
----
NAME                  DESIRED   CURRENT   READY   AGE
parksmap-65c4f8b676   1         1         1       21m
----

这让我们知道，现在我们期望部署一个Pod ( Desired)，而我们实际部署了一个Pod ( Current)。通过更改所需的数量，我们可以告诉 OpenShift 我们想要更多或更少的Pods。

OpenShift 的Horizo​​ntalPodAutoscaler有效地监控一组实例的 CPU 使用率，然后相应地操纵 RC。

您可以在此处了解有关基于 CPU 的
{openshift-docs-url}/nodes/pods/nodes-pods-autoscaling.html#nodes-pods-autoscaling-about_nodes-pods-autoscaling[Horizontal Pod Autoscaler]的更多信息

[#scaling_the_application]
== 练习：扩展应用程序

让我们将我们的 parkmap“应用程序”扩展到 2 个实例。我们可以使用scale命令来做到这一点。您也可以通过增加 OpenShift Web 控制台中的 Desired Count 来完成此操作。选择其中一种方法；由您决定。

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc scale --replicas=2 deployment/parksmap
----

您还可以在Developer Perspective 中最多扩展两个 Pod 。在拓扑视图中，首先单击parksmap部署配置并选择详细信息选项卡：

image::parksmap-details.png[Details]

接下来，单击Pod 可视化旁边的 *^* 图标以扩展到 2 个 Pod

image::parksmap-scaleup.png[Scaling Up]

要验证我们是否更改了副本数，请输入以下命令

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get rs
----

[.console-output]
[source,bash]
----
NAME                  DESIRED   CURRENT   READY   AGE
parksmap-65c4f8b676   2         2         2       23m
----

您可以看到我们现在有 2 个副本。让我们使用以下oc get pods命令验证 Pod 的数量：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get pods
----

[.console-output]
[source,bash]
----
NAME                        READY   STATUS    RESTARTS   AGE
parksmap-65c4f8b676-fxcrq   1/1     Running   0          92s
parksmap-65c4f8b676-k5gkk   1/1     Running   0          24m
----

最后，让我们验证我们在 *上一个实验* 中了解到的Service是否准确反映了两个端点endpoint：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc describe svc parksmap
----

您将看到类似于以下输出的内容：

[.console-output]
[source,bash]
----
Name:              parksmap
Namespace:         user1
Labels:            app=workshop
                   app.kubernetes.io/component=parksmap
                   app.kubernetes.io/instance=parksmap
                   app.kubernetes.io/part-of=workshop
                   component=parksmap
                   role=frontend
Annotations:       openshift.io/generated-by: OpenShiftWebConsole
Selector:          app=parksmap,deploymentconfig=parksmap
Type:              ClusterIP
IP:                172.30.22.209
Port:              8080-tcp  8080/TCP
TargetPort:        8080/TCP
Endpoints:         10.128.2.90:8080,10.131.0.40:8080
Session Affinity:  None
Events:            <none>
----

查看Service端点的另一种方法是使用以下方法：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get endpoints parksmap
----

你会看到如下内容：

[.console-output]
[source,bash]
----
NAME       ENDPOINTS                           AGE
parksmap   10.128.2.90:8080,10.131.0.40:8080   45m
----

您的 IP 地址可能会有所不同，因为每个 pod 在 OpenShift 环境中都会收到一个唯一的 IP。*端点列表是查看服务背后有多少 Pod 的快速方法* 。

您还可以在 Developer Perspective 中看到两个Pod都在运行：

image::parksmap-scaled.png[Scaled]

总的来说，在service中伸缩pod是非常简单的。应用程序扩展可以非常快地发生，因为 OpenShift 只是启动现有镜像的新实例，特别是如果该图像已经缓存在节点上

[#application_self_healing]
== Application "Self Healing"

由于 OpenShift 的RS会不断监控以查看实际运行的Pod数量是否达到预期，因此您可能还期望 OpenShift 会在出现问题时“修复fix”这种情况，的确如此。

由于我们现在有两个Pod正在运行，让我们看看如果我们“意外”杀死一个会发生什么。oc get pods再次运行该命令，并选择一个Pod 名称。然后，执行以下操作：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc delete pod parksmap-65c4f8b676-k5gkk && oc get pods
----

[.console-output]
[source,bash]
----
pod "parksmap-65c4f8b676-k5gkk" deleted
NAME                        READY   STATUS    RESTARTS   AGE
parksmap-65c4f8b676-bjz5g   1/1     Running   0          13s
parksmap-65c4f8b676-fxcrq   1/1     Running   0          4m48s
----

你注意到什么了吗？一个容器已被删除，并且已经创建了一个新容器。

此外，Pod的名称也略有更改。这是因为 OpenShift 几乎立即检测到当前状态 (1 Pod ) 与所需状态 (2 Pods )不匹配，并通过调度另一个Pod来修复它。

此外，OpenShift 提供了有关检查应用程序实例的活跃度和/或准备情况的基本功能。如果基本检查不足，OpenShift 还允许您在容器内运行命令以执行检查。该命令可以是使用任何已安装语言的复杂脚本。

基于这些健康检查，如果 OpenShift 确定我们的parksmap 应用程序实例不活跃，它会杀死该实例然后重新启动它，始终确保所需数量的副本到位。

有关探测应用程序的更多信息，请参见文档的
{openshift-docs-url}/applications/application-health.html[ 应用程序运行状态健康 Application
Health] 小节以及本指南的后面部分

[#scale_down]
== 练习：缩小 Scale Down

在我们继续之前，请继续将您的应用程序缩小到单个实例。随意使用您喜欢的任何方法来执行此操作。

WARNING: 不要忘记将parksmap组件缩小到 1 个实例，否则在以后的实验中您可能会遇到一些奇怪的行为。这是由于应用程序的编码方式而不是 OpenShift 本身。
