= Parksmap App
:navtitle: Parksmap App

在本实验中，我们将部署 ParksMap 应用程序的 Web 组件，该应用程序也称为parksmap，并使用 OpenShift 的服务发现机制来发现部署的后端服务并在地图上显示其数据。

image::roadshow-app-architecture-parksmap-1.png[Application architecture,800,align="center"]

[#deploy_your_first_image]
== 练习: 部署您的第一个镜像 Deploying your First Image

让我们从做最简单的事情开始 - 获取一个Docker 格式的图像以在 OpenShift 上运行。这非常简单。使用 OpenShift，它可以直接从 Web 控制台完成。

返回到 https://console-openshift-console.%CLUSTER_SUBDOMAIN%/k8s/cluster/projects[Web Console, role='params-link', window='_blank'].

如果您不再处于开发人员视图，请立即返回。

从左侧菜单中，单击+添加。您将看到一个屏幕，您可以在其中使用多个选项将应用程序部署到 OpenShift。点击*容器镜像*  *Container Image* 打开一个对话框，您可以在其中指定要部署的映像的信息。

image::parksmap-devconsole-container-image.png[Add from Container Image]

在镜像名称字段中，将以下内容复制/粘贴到框中：

[source,role=copypaste,subs="+macros,+attributes"]
----
{parksmap-image}:{parksmap-version}
----

然后OpenShift将转到指定的容器注册表并查询图像。

您的屏幕最终将看起来像这样：

image::parksmap-image.png[Explore Project]

在运行时图标*Runtime Icon*中，您可以选择要在应用程序的 OpenShift 拓扑视图中使用的图标。你可以保留默认的 OpenShift 图标，或者因为这个前端是用 Spring Boot 制作的，你可以选择spring-boot。

确保在以下位置变量数值正确：

*Application Name* :
[source,role=copypaste]
----
workshop
----

*Name* :
[source,role=copypaste]
----
parksmap
----

确保从资源*Resource*部分选择部署*Deployment* 。

NOTE: 我们将在下一章详细讨论Deployment和DeploymentConfig。

取消选中Create a route to the application旁边的复选框。出于学习目的，我们将在实验的稍后部分为应用程序创建一个路由。

在页面的底部，点击标签在高级选项部分，并添加一些标签*Labels*以后更好地识别此部署。标签将帮助我们在 Web 控制台和命令行中识别和过滤组件。

我们将添加 3 个标签 为每个标签输入名称=值对后，在键入下一个标签前, 按 kbd:[Return] (或 kbd:[Enter] 取决于您的键盘) 以输入下一个标签。我们将输入的第一个标签是应用程序的名称：

[source,role=copypaste]
----
app=workshop
----

接下来是此部署deployment的名称。

[source,role=copypaste]
----
component=parksmap
----

最后，标记这个组件在整个应用程序中扮演的角色

[source,role=copypaste]
----
role=frontend
----


image::parksmap-image-options.png[Deploy image]

接下来，单击蓝色的创建按钮。您将被定向到拓扑页面，您应该在其中看到应用程序中parksmap部署配置的可视化workshop。

image::parksmap-dc-topology.png[Topology View with Parksmap]

您在 OpenShift 上部署容器映像只需要这几个步骤。这应该适用于任何遵循最佳实践的容器镜像，例如定义一个 EXPOSE 端口，不需要专门作为root 用户或其他用户名运行，以及在启动容器时执行非退出命令。

[NOTE]
====
翻译附注：由于openshift在安全、功能等方面在k8s基础上做了很多修改及增强，所以强烈建议参考红帽openshift官方文档，《学习容器最佳实践》章节，（您可能需要红帽订阅或免费申请红帽开发者账号）https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.8/html/images/creating-images#images-create-guidelines_create-images
====



NOTE: 出于组织目的部署复杂应用程序时，需要使用适当的标签标记使用的资源。OpenShift 使用标签应用程序在概览页面中定义和分组组件资源。如果用户未明确提供，OpenShift 将使用一些默认值创建此标签。

[#containers_and_pods]
== 背景: 容器和pods Containers and Pods

在开始深入研究之前，我们需要了解容器和Pod之间的关系。我们不会在本实验室中介绍这些技术的背景，但如果您有任何疑问，请告知讲师。下面我们将深入研究并开始使用它们。

在 OpenShift （k8s)中，最小的可部署单元是Pod， *Pod*是一组部署在一起并保证位于同一主机上的一个或多个OCI容器。
来自官方 OpenShift 文档：

[quote]
__
每个Pod都有自己的 IP 地址，因此拥有自己的整个端口空间port space，Pod 内的容器可以共享存储。Pod可以用一个或多个标签“标记”，然后用于在单个操作中选择和管理Pod组。
__

Pod可以包含多个 OCI 容器。总体思路是让Pod包含一个“主进程”以及您希望与该进程一起运行的任何辅助服务。例如您可以在Pod中放置的容器包括Apache HTTPD 服务器、日志分析器和帮助管理上传文件的文件服务。

[#examining_the_pod]
== 练习：查看 Pod信息

如果单击parksmap拓扑视图中的条目，您将看到有关该部署配置的一些信息。在资源选项卡可能被默认显示。如果是这样，请单击“详细信息”选项卡。

image::switchtoresources.png[Details Tab image]

在该面板上，您将看到有一个由您的操作创建的Pod。

image::parksmap-overview.png[Pod overview]

NOTE: 您会在此视图中注意到一个信息框，建议为我们的应用添加健康检查。我们将在稍后详细讨论它，因此目前您只需单击右上角的 X 图标即可关闭此信息框。

您还可以通过导航到Web控制台的管理员视图下的工作负载→Pods来获取项目中创建的所有Pods的列表。

image::parksmap-podlist.png[Pod list]

此Pod包含一个容器，parksmap应用程序——一个简单的Spring Boot/Java应用程序。

您还可以从命令行检查Pod：

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get pods
----

您应该会看到类似于以下内容的输出：

[.console-output]
[source,bash]
----
NAME                READY   STATUS      RESTARTS   AGE
parksmap-65c4f8b676-k5gkk    1/1     Running     0          20s
----

上述输出列出了当前项目中的所有Pod，包括Pod名称、状态、重新启动和正常运行时间。

获得Pod名称后，您可以使用oc get命令获取有关Pod的更多信息。为了使输出可读，我建议使用以下语法将输出类型更改为YAML：

NOTE: 确保您使用了刚刚屏幕输出中的正确Pod名称。

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get pod parksmap-1-gxbgq -o yaml
----

您应该会看到类似于以下输出的内容（由于本实验手册的篇幅原因已被截断）：

[source,text]
----
apiVersion: v1
kind: Pod
metadata:
  annotations:
    k8s.v1.cni.cncf.io/network-status: |-
      [{
          "name": "",
          "interface": "eth0",
          "ips": [
              "10.131.0.93"
          ],
          "default": true,
          "dns": {}
      }]
    k8s.v1.cni.cncf.io/networks-status: |-
      [{
          "name": "",
          "interface": "eth0",
          "ips": [
              "10.131.0.93"
          ],
          "default": true,
          "dns": {}
      }]
    openshift.io/generated-by: OpenShiftWebConsole
    openshift.io/scc: restricted
  creationTimestamp: "2021-01-05T17:00:32Z"
  generateName: parksmap-65c4f8b676-
  labels:
    app: parksmap
    component: parksmap
    deploymentconfig: parksmap
    pod-template-hash: 65c4f8b676
    role: frontend
...............
----

Web 界面还在Pod详细信息页面上显示了许多相同的信息。如果您点击Pod的名称，您将找到详细信息页面。您还可以通过单击拓扑 Topology 页面上的parksmap部署配置，选择 资源 Resources，然后单击Pod名称来到达那里。

image::parksmap-dc-resources.png[Parksmap Resources]

从这里您可以看到配置、指标、环境变量、日志、事件，并可以在正在运行的 pod 上获取终端 shell。

image::parksmap-pod.png[Pod Details]

image::parksmap-pod-events.png[Pod Events]

获取parksmap 镜像运行，可能需要一段时间才能完成。如果节点尚未在本地缓存它，则要求运行该映像的每个 OpenShift 节点都必须拉取（下载）它。您可以在Pod详细信息页面中查看映像下载和部署的状态，也可以使用之前使用的命令oc get pods从命令行查看。

Developer控制台中的默认视图是Graph View。您可以使用控制台右上角的切换按钮在图表和列表视图之间切换。

image::nationalparks-listview.png[List View Toggle]

image::nationalparks-graphview.png[Topology View Toggle]

[#customizing_image_lifecycle_behavior]
== 背景：自定义图像生命周期行为

每当 OpenShift 要求节点的 CRI（容器运行时接口）运行时（Docker 守护程序或 CRI-O）运行映像时，运行时都会检查以确保它具有要运行的正确“版本”映像。如果没有，它将从指定的镜像仓库中提取它。


有多种方法可以自定义此行为。它们记录在 指定映像 以及 映像拉取策略中。
{openshift-docs-url}/applications/application_life_cycle_management/creating-applications-using-cli.html#applications-create-using-cli-image_creating-applications-using-cli[specifying an image]
as well as
{openshift-docs-url}/openshift_images/managing_images/image-pull-policy.html[image pull policy].

[#services]
== Background: Services

*Services* provide a convenient abstraction layer inside OpenShift to find a
group of similar *Pods*. They also act as an internal proxy/load balancer between
those *Pods* and anything else that needs to access them from inside the
OpenShift environment. For example, if you needed more `parksmap` instances to
handle the load, you could spin up more *Pods*. OpenShift automatically maps
them as endpoints to the *Service*, and the incoming requests would not notice
anything different except that the *Service* was now doing a better job handling
the requests.

When you asked OpenShift to run the image, it automatically created a *Service*
for you. Remember that services are an internal construct. They are not
available to the "outside world", or anything that is outside the OpenShift
environment. That's okay, as you will learn later.

The way that a *Service* maps to a set of *Pods* is via a system of *Labels* and
*Selectors*. *Services* are assigned a fixed IP address and many ports and
protocols can be mapped.

There is a lot more information about
{openshift-docs-url}/architecture/understanding-development.html#understanding-kubernetes-pods[Services],
including the YAML format to make one by hand, in the official documentation.

Now that we understand the basics of what a *Service* is, let's take a look at
the *Service* that was created for the image that we just deployed. In order to
view the *Services* defined in your *Project*, enter in the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get services
----

You should see output similar to the following:

[.console-output]
[source,bash]
----
NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
parksmap   ClusterIP   172.30.22.209  <none>        8080/TCP   3h
----

In the above output, we can see that we have a *Service* named `parksmap` with an
IP/Port combination of 172.30.22.209/8080TCP. Your IP address may be different, as
each *Service* receives a unique IP address upon creation. *Service* IPs are
fixed and never change for the life of the *Service*.

In the Developer perspective from the *Topology* view, service information is available by clicking the `parksmap` deployment config, then *Resources*, and then you should see the `parksmap` entry in the *Services* section.

image::parksmap-serviceslist.png[Services list]

You can also get more detailed information about a *Service* by using the
following command to display the data in YAML:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get service parksmap -o yaml
----

You should see output similar to the following:

[.console-output]
[source,text]
----
apiVersion: v1
kind: Service
metadata:
  annotations:
    openshift.io/generated-by: OpenShiftWebConsole
  creationTimestamp: "2020-09-30T14:10:12Z"
  labels:
    app: workshop
    app.kubernetes.io/component: parksmap
    app.kubernetes.io/instance: parksmap
    app.kubernetes.io/part-of: workshop
    component: parksmap
    role: frontend
  name: parksmap
  namespace: workshop
  resourceVersion: "1062269"
  selfLink: /api/v1/namespaces/workshop/services/parksmap
  uid: e1ff69c8-cb2f-11e9-82a1-0267eec7e1a0
spec:
  clusterIP: 172.30.22.209
  ports:
  - name: 8080-tcp
    port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app: parksmap
    deploymentconfig: parksmap
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
----

Take note of the `selector` stanza. Remember it.

Alternatively, you can use the web console to view information about the *Service* by clicking on it from the previous screen.

image::parksmap-service.png[Service]

It is also of interest to view the YAML of the *Pod* to understand how OpenShift
wires components together. For example, run the following command to get the
name of your `parksmap` *Pod*:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get pods
----

You should see output similar to the following:

[.console-output]
[source,bash]
----
NAME                        READY   STATUS    RESTARTS   AGE
parksmap-65c4f8b676-k5gkk   1/1     Running   0          5m12s
----

Now you can view the detailed data for your *Pod* with the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc get pod parksmap-1-gxbgq -o yaml
----

Under the `metadata` section you should see the following:

[.console-output]
[source,bash]
----
  labels:
    app: parksmap
    deploymentconfig: parksmap
----

* The *Service* has `selector` stanza that refers to `deploymentconfig=parksmap`.
* The *Pod* has multiple *Labels*:
** `app=parksmap`
** `deploymentconfig=parksmap`

*Labels* are just key/value pairs. Any *Pod* in this *Project* that has a *Label* that
matches the *Selector* will be associated with the *Service*. To see this in
action, issue the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
oc describe service parksmap
----

You should see something like the following output:

[.console-output]
[source,text]
----
Name:              parksmap
Namespace:         workshop
Labels:            app=workshop
                   app.kubernetes.io/component=parksmap
                   app.kubernetes.io/instance=parksmap
                   app.kubernetes.io/part-of=workshop
                   component=parksmap
                   role=frontend
Annotations:       openshift.io/generated-by: OpenShiftWebConsole
Selector:          app=parksmap,deploymentconfig=parksmap
Type:              ClusterIP
IP:                172.30.22.209
Port:              8080-tcp  8080/TCP
TargetPort:        8080/TCP
Endpoints:         10.128.2.90:8080
Session Affinity:  None
Events:            <none>
----

You may be wondering why only one endpoint is listed. That is because there is
only one *Pod* currently running.  In the next lab, we will learn how to scale
an application, at which point you will be able to see multiple endpoints
associated with the *Service*.
